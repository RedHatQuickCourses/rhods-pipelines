<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Introduction :: Automation using Data Science Pipelines</title>
    <link rel="prev" href="index.html">
    <link rel="next" href="section2.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">Automation using Data Science Pipelines</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/rhods-pipelines/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header><div class="body">
<div class="nav-container" data-component="rhods-pipelines" data-version="1.33">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Automation using Data Science Pipelines</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="index.html">Data Science Pipelines</a>
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="section1.html">Introduction</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="section2.html">Elyra Pipelines</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="section3.html">Kubeflow SDK</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Automation using Data Science Pipelines</span>
    <span class="version">1.33</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">Automation using Data Science Pipelines</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1.33</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Automation using Data Science Pipelines</a></li>
    <li><a href="index.html">Data Science Pipelines</a></li>
    <li><a href="section1.html">Introduction</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Introduction</h1>
<div class="sect1">
<h2 id="_data_science_pipeline_concepts"><a class="anchor" href="#_data_science_pipeline_concepts"></a>Data Science Pipeline Concepts</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><strong>Pipeline</strong> -  is a workflow definition containing the steps and their input and output artifacts.</p>
</li>
<li>
<p><strong>Step</strong> - is a self-contained pipeline component that represents an execution stage in the pipeline.</p>
</li>
<li>
<p><strong>Experiment</strong> - is a logical grouping of runs for the purpose of comparing different pipeline configurations, for instance.</p>
</li>
<li>
<p><strong>Run</strong> - is a <em>single</em> execution of a pipeline whereas a <em>recurring run</em> is a scheduled, repeated execution of a pipeline.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>A pipeline is an execution graph of tasks, commonly known as a <em>DAG</em> (Directed Acyclic Graph).
A DAG is a directed graph without any cycles, i.e. direct loops.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>A data science pipeline typically consists of several key activities that are performed in a structured sequence to transform raw data into meaningful insights or predictions. These activities may include:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Data Collection</strong>: Gathering the data from various sources, such as databases, APIs, spreadsheets, or external datasets.</p>
</li>
<li>
<p><strong>Data Cleaning</strong>: Identifying and handling missing or inconsistent data, removing duplicates, and addressing data quality issues to ensure that the data is reliable and ready for analysis.</p>
</li>
<li>
<p><strong>Data Exploration</strong>: Exploring the data to understand its characteristics, including summary statistics, data distributions, and visualizations. This step helps in gaining insights into the data and identifying potential patterns or outliers.</p>
</li>
<li>
<p><strong>Feature Engineering</strong>: Creating or transforming features (variables) to improve the performance of machine learning models. This may involve scaling, one-hot encoding, creating new variables, or reducing dimensionality.</p>
</li>
<li>
<p><strong>Data Preprocessing</strong>: Preparing the data for modeling, which may involve standardizing, normalizing, or scaling the data. This step is crucial for machine learning algorithms that are sensitive to the scale of features.</p>
</li>
<li>
<p><strong>Model Building</strong>: Developing machine learning or statistical models to solve a specific problem or make predictions. This step includes selecting an appropriate algorithm, training the model, and fine-tuning its hyperparameters.</p>
</li>
<li>
<p><strong>Model Evaluation</strong>: Assessing the performance of the model using various metrics, such as accuracy, precision, recall, F1 score, or mean squared error. Cross-validation techniques may be used to ensure the model&#8217;s robustness.</p>
</li>
<li>
<p><strong>Model Deployment</strong>: Integrating the trained model into a production environment so that it can make real-time predictions or recommendations. This may involve creating APIs, web applications, or embedding the model in an existing software system.</p>
</li>
<li>
<p><strong>Monitoring and Maintenance</strong>: Continuously monitoring the deployed model&#8217;s performance and making necessary updates or retraining when the model&#8217;s accuracy decreases over time due to changing data distributions or other factors.</p>
</li>
<li>
<p><strong>Reporting and Visualization</strong>: Communicating the results and insights to stakeholders through reports, dashboards, or interactive visualizations, making it easier for non-technical audiences to understand the findings.</p>
</li>
<li>
<p><strong>Documentation</strong>: Creating documentation for the entire data science pipeline, including data sources, data processing steps, model details, and evaluation metrics. This documentation is essential for reproducibility and collaboration.</p>
</li>
<li>
<p><strong>Collaboration and Communication</strong>: Collaborating with domain experts, stakeholders, and other team members to define project objectives, gather domain knowledge, and align the data science work with the business goals.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These activities are typically iterative and may involve going back and forth between different stages to refine the analysis and models. Data science pipelines can vary depending on the specific project and organization, but these general steps provide a framework for approaching data science tasks.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_data_science_pipelines_in_openshift_ai"><a class="anchor" href="#_data_science_pipelines_in_openshift_ai"></a>Data Science Pipelines in OpenShift AI</h2>
<div class="sectionbody">
<div class="paragraph">
<p>From the perspective of a data scientist or ML engineer user experience, OpenShift AI provides several user interface capabilities trying to cover as many as possible from these data science activities. It includes the following</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Data Science Pipelines Main View</strong> - End users can find the pipelines to whom they have access under the data science pipelines menu / main view</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/dsps-main.png" alt="Data Science Pipelines Menu / Main View">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Data Science Pipelines Runs</strong> - When looking for more details, end users explore the runs of their data science pipelines</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/dsps-runs.png" alt="Data Science Pipelines Runs">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Data Science Pipelines view within a Data Science Project</strong> - While within their data science project, end users can visualise the runs and other details of pipelines that ran within that project.</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/dsps-in-ds-project.png" alt="Data Science Pipelines view within a Data Science Project">
</div>
</div>
<div class="paragraph">
<p>Those data scientists and ML engineers with access to and knowledge of containers and OpenShift, can also look "under the covers" and check their pipeline runs direct in OpenShift:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>OpenShift Pipeline executing a Data Science Pipeline</strong> - From the OpenShift Console, under Pipelines&#8594;PipelinesRuns one can see the underlying Tekton pipeline that runs in OCP, once a data scientist started a Data Science Pipeline in OpenShift AI</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/dsp-run-in-ocp-pipelines.png" alt="OpenShift Pipeline executing a Data Science Pipeline">
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_data_science_pipelines_technologies"><a class="anchor" href="#_data_science_pipelines_technologies"></a>Data Science Pipelines Technologies</h2>
<div class="sectionbody">
<div class="paragraph">
<p>At a high level, here are the technologies used to implement Data Science Pipelines in OpenShift AI:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Elyra Pipelines</strong> - A <strong>JupyterLab</strong> extension, which provides a visual editor for creating data science pipelines based on Jupyter notebooks as well as Python or R scripts. User can drag and drop code and create visually such pipelines</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/elyra-pipeline-offline-scoring.png" alt="An Offline Scoring pipeline in Elyra">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/elyra-pipeline-model-training.png" alt="A Model Training pipeline in Elyra">
</div>
</div>
<div class="paragraph">
<p>A data scientist can assign resources visually, including CPUs and GPUs, to each individual step in the pipeline.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/elyra-pipeline-step-config-with-gpu.png" alt="Configuring GPUs and other resources for an Elyra pipeline step">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Kubeflow Pipelines</strong> - Specialized data science pipelines engine which can translate an Elyra visual pipeline execution (or Kubeflow SDK calls) into a <strong>Tekton</strong> pipeline running in OpenShift.</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/elyra-pipeline-running.png" alt="Starting an Elyra pipeline">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/elyra-pipeline-job-started.png" alt="Details of a started Elyra pipeline">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>OpenShift Pipelines (based on Tekton)</strong> - It executes each step in the pipeline as an individual container and ensures that each container gets allocated the resources (GPU, CPU, memory) configured/requested by data scientists in Elyra (or via Kubeflow SDK), as long as they are available in the OpenShift cluster.</p>
</li>
<li>
<p><strong>OpenShift GitOps with ArgoCD for automated model deployments</strong> - While not part of the OpenShift AI but rather as part of OpenShift, it is worth mentioning that once ML models are created, GitOps can be leveraged to push them to other OpenShift instances (including OpenShift Edge devices) for being hosted on model servers for inference and/or embedded in intelligent apps.</p>
</li>
</ul>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="index.html">Data Science Pipelines</a></span>
  <span class="next"><a href="section2.html">Elyra Pipelines</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
